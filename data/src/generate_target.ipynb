{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2364d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2ba36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b9ebc6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/hongrudu/Documents/GitHub/PandemicLLM/data/src/raw_data/static_variable_state.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m static \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/raw_data/static_variable_state.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pop \u001b[38;5;241m=\u001b[39m static[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfips\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPopulation\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/hongrudu/Documents/GitHub/PandemicLLM/data/src/raw_data/static_variable_state.pkl'"
     ]
    }
   ],
   "source": [
    "static = pd.read_pickle(cwd + '/raw_data/static_variable_state.pkl')\n",
    "pop = static[['fips', 'Population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a931196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/qtvw7sp54r91rm2skfzzb8ww0000gn/T/ipykernel_29365/3509825895.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  hosp_week = hosp.groupby(['state_name', 'Variable', 'fips', 'Week', 'Description']).sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "hosp = pd.read_pickle(cwd + '/processed_data/hospitalization_daily_state.pkl')\n",
    "hosp['Week'] = hosp['Date'].dt.to_period('W')\n",
    "hosp_week = hosp.groupby(['state_name', 'Variable', 'fips', 'Week', 'Description']).sum().reset_index()\n",
    "hosp_week = hosp_week.merge(pop)\n",
    "hosp_week['hospitalization_per_100k'] = (hosp_week['value']/hosp_week['Population'])*100000\n",
    "hosp_week = hosp_week.drop(columns = {'Variable', 'Description'})\n",
    "hosp_week['Week_start'] = hosp_week['Week'].apply(lambda r: r.start_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "hosp_week['Week_end'] = hosp_week['Week'].apply(lambda r: r.end_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "hosp_week = hosp_week.rename(columns = {'value' : 'hospitalization'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e71f8",
   "metadata": {},
   "source": [
    "### Week1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a8230a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Smooth hosp\n",
    "for fips in hosp_week['fips'].unique():\n",
    "    index = hosp_week[hosp_week['fips'] == fips].index\n",
    "    hosp_week.loc[index, 'hospitalization_per_100k_sm'] = \\\n",
    "    hosp_week[hosp_week['fips'] == fips]['hospitalization_per_100k'].rolling(window = 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f129911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips in hosp_week['fips'].unique():\n",
    "    index = hosp_week[hosp_week['fips'] == fips].index\n",
    "    hosp_week.loc[index, 'hospitalization_per_100k_sm_lag1'] = \\\n",
    "    hosp_week[hosp_week['fips'] == fips]['hospitalization_per_100k_sm'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "858434e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_week = hosp_week.dropna().reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "35582b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_week['Abs_Change_w1'] = hosp_week['hospitalization_per_100k'] - hosp_week['hospitalization_per_100k_sm_lag1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dfdcdf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_week['Abs_Change_w1'] = round(hosp_week['Abs_Change_w1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a7c39be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define threshold\n",
    "'''\n",
    "# hosp_week['Change'] = (hosp_week['hospitalization_per_100k'] - hosp_week['hospitalization_per_100k_lag1'])\\\n",
    "# /hosp_week['hospitalization_per_100k_lag1']\n",
    "\n",
    "\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w1'] < 1)&(hosp_week['Abs_Change_w1'] >= -1)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Stable'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w1'] >= 1)&(hosp_week['Abs_Change_w1'] < 3)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Moderate Increasing'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w1'] >= 3)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Substantial Increasing'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w1'] > -3)&(hosp_week['Abs_Change_w1'] <= -1)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Moderate Decreasing'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w1'] <= -3)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Substantial Decreasing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fb804ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in hosp_week[hosp_week['Week_end'] >= '2021-01-01'].iterrows():\n",
    "    prompt = \"The most recent hospitalization trends are: \" + hosp_week.loc[index-4, 'Abs_Trend'].upper() +\\\n",
    "    ', ' + hosp_week.loc[index-3, 'Abs_Trend'].upper() +\\\n",
    "    ', ' + hosp_week.loc[index-2, 'Abs_Trend'].upper() +\\\n",
    "    ', ' + hosp_week.loc[index-1, 'Abs_Trend'].upper() + ', and ' + hosp_week.loc[index, 'Abs_Trend'].upper()\n",
    "    hosp_week.loc[index, 'Trend_prompt'] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "943e0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips in hosp_week['fips'].unique():\n",
    "    index = hosp_week[hosp_week['fips'] == fips].index\n",
    "    hosp_week.loc[index, 'Abs_Trend_1w'] = hosp_week.loc[index, 'Abs_Trend'].shift(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b835f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_week = hosp_week.rename(columns = {'Abs_Change_w1' : 'Abs_Change'})\n",
    "hosp_week = hosp_week.rename(columns = {'Abs_Trend_1w' : 'Abs_Trend_target_1w'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bb63b5",
   "metadata": {},
   "source": [
    "### Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4295d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.read_pickle(cwd + '/processed_data/confimed_cases_daily_state.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c588bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/qtvw7sp54r91rm2skfzzb8ww0000gn/T/ipykernel_29365/1334263650.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  cases_week = cases.groupby(['Week', 'state_name', 'fips','Description']).sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "cases['Week'] = cases['Date'].dt.to_period('W')\n",
    "cases_week = cases.groupby(['Week', 'state_name', 'fips','Description']).sum().reset_index()\n",
    "cases_week['Week_start'] = cases_week['Week'].apply(lambda r: r.start_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "cases_week['Week_end'] = cases_week['Week'].apply(lambda r: r.end_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "cases_week = cases_week.rename(columns = {'value' : 'Reported_cases'}).drop(columns = ['Description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "07d539d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips in cases_week['fips'].unique():\n",
    "    index = cases_week[cases_week['fips'] == fips].index\n",
    "    cases_week.loc[index, 'previous_infection_12w'] = \\\n",
    "    cases_week[cases_week['fips'] == fips]['Reported_cases'].rolling(window = 12, min_periods = 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0acd2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hosp_week.merge(cases_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "24be77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'Population' : 'population', 'Reported_cases' : 'reported_cases'})\n",
    "df['reported_cases_per_100k'] = (df['reported_cases']/df['population'])*100000\n",
    "df['reported_cases_per_100k'] = round(df['reported_cases_per_100k'],1)\n",
    "df['previous_infection_12w'] = round((df['previous_infection_12w']/df['population'])*100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4951aa",
   "metadata": {},
   "source": [
    "### Vaccine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2ba9846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc = pd.read_pickle(cwd + '/processed_data/vaccination_weekly_state.pkl')\n",
    "vacc['dow'] = vacc['Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4b83554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/qtvw7sp54r91rm2skfzzb8ww0000gn/T/ipykernel_29365/314402433.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  vacc_week = vacc.groupby(['Week', 'state_name', 'fips', 'Variable', 'Description']).mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "vacc['Week'] = vacc['Date'].dt.to_period('W')\n",
    "vacc_week = vacc.groupby(['Week', 'state_name', 'fips', 'Variable', 'Description']).mean().reset_index()\n",
    "vacc_week['Week_start'] = vacc_week['Week'].apply(lambda r: r.start_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "vacc_week['Week_end'] = vacc_week['Week'].apply(lambda r: r.end_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6c564439",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_week = vacc_week.drop(columns = ['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6d99fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(vacc_week[vacc_week['Variable'] == 'Administered_Dose1_Pop_Pct'])\n",
    "df = df.rename(columns = {'value': 'Dose1_Pop_Pct'}).drop(columns = ['Variable'])\n",
    "df = df.merge(vacc_week[vacc_week['Variable'] == 'Series_Complete_Pop_Pct'])\n",
    "df = df.rename(columns = {'value': 'Series_Complete_Pop_Pct'}).drop(columns = ['Variable'])\n",
    "df = df.merge(vacc_week[vacc_week['Variable'] == 'Additional_Doses_Vax_Pct'])\n",
    "df = df.rename(columns = {'value': 'Additional_Doses_Vax_Pct'}).drop(columns = ['Variable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e8a21",
   "metadata": {},
   "source": [
    "### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0d68d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = pd.read_pickle(cwd +'/processed_data/selected_state_policy_daily.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b90075a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy['Week'] = policy['Date'].dt.to_period('W')\n",
    "policy['Week_start'] = policy['Week'].apply(lambda r: r.start_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "policy['Week_end'] = policy['Week'].apply(lambda r: r.end_time).dt.to_period('D').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6de55481",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = policy[pd.to_datetime(policy['Date']) == policy['Week_end']].reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4218a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(policy)\n",
    "df = df.drop(columns = ['population'])\n",
    "df = df.drop(columns = ['state_abbr', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d76d38",
   "metadata": {},
   "source": [
    "### Week 3 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cff2c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp = pd.read_pickle('/Users/hongrudu/Documents/Projects/COVIDLLM/data/processed_data/hospitalization_daily_state.pkl')\n",
    "hosp['Week'] = hosp['Date'].dt.to_period('W')\n",
    "hosp_week = hosp.drop(columns = ['Date', 'State', 'Temporal_resolution']).groupby(['state_name', 'Variable', 'fips', 'Week', 'Description']).sum().reset_index()\n",
    "hosp_week = hosp_week.merge(pop)\n",
    "hosp_week['hospitalization_per_100k'] = (hosp_week['value']/hosp_week['Population'])*100000\n",
    "hosp_week = hosp_week.drop(columns = {'Variable', 'Description'})\n",
    "hosp_week['Week_start'] = hosp_week['Week'].apply(lambda r: r.start_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "hosp_week['Week_end'] = hosp_week['Week'].apply(lambda r: r.end_time).dt.to_period('D').dt.strftime('%Y-%m-%d')\n",
    "hosp_week = hosp_week.rename(columns = {'value' : 'hospitalization'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "352e4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Smooth hosp\n",
    "for fips in hosp_week['fips'].unique():\n",
    "    index = hosp_week[hosp_week['fips'] == fips].index\n",
    "    hosp_week.loc[index, 'hospitalization_per_100k_sm'] = \\\n",
    "    hosp_week[hosp_week['fips'] == fips]['hospitalization_per_100k'].rolling(window = 3).mean()\n",
    "\n",
    "for fips in hosp_week['fips'].unique():\n",
    "    index = hosp_week[hosp_week['fips'] == fips].index\n",
    "    hosp_week.loc[index, 'hospitalization_per_100k_sm_lag3'] = \\\n",
    "    hosp_week[hosp_week['fips'] == fips]['hospitalization_per_100k_sm'].shift(3)\n",
    "\n",
    "hosp_week = hosp_week.dropna().reset_index().drop(columns = ['index'])\n",
    "hosp_week['Abs_Change_w3'] = hosp_week['hospitalization_per_100k'] - hosp_week['hospitalization_per_100k_sm_lag3']\n",
    "hosp_week['Abs_Change_w3'] = round(hosp_week['Abs_Change_w3'], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "527a4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define threshold\n",
    "'''\n",
    "# hosp_week['Change'] = (hosp_week['hospitalization_per_100k'] - hosp_week['hospitalization_per_100k_lag1'])\\\n",
    "# /hosp_week['hospitalization_per_100k_lag1']\n",
    "\n",
    "\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w3'] < 1.5)&(hosp_week['Abs_Change_w3'] >= -1.5)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Stable'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w3'] >= 1.5)&(hosp_week['Abs_Change_w3'] < 4.5)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Moderate Increasing'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w3'] >= 4.5)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Substantial Increasing'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w3'] > -4.5)&(hosp_week['Abs_Change_w3'] <= -1.5)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Moderate Decreasing'\n",
    "index_stable = hosp_week[(hosp_week['Abs_Change_w3'] <= -4.5)].index\n",
    "hosp_week.loc[index_stable, 'Abs_Trend'] = 'Substantial Decreasing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ec76099",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in hosp_week[hosp_week['Week_end'] >= '2021-01-01'].iterrows():\n",
    "    prompt = \"The most recent hospitalization trends are: \" + hosp_week.loc[index-4, 'Abs_Trend'].upper() +\\\n",
    "    ', ' + hosp_week.loc[index-3, 'Abs_Trend'].upper() +\\\n",
    "    ', ' + hosp_week.loc[index-2, 'Abs_Trend'].upper() +\\\n",
    "    ', ' + hosp_week.loc[index-1, 'Abs_Trend'].upper() + ', and ' + hosp_week.loc[index, 'Abs_Trend'].upper()\n",
    "    hosp_week.loc[index, 'Trend_prompt'] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a30b91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fips in hosp_week['fips'].unique():\n",
    "    index = hosp_week[hosp_week['fips'] == fips].index\n",
    "    hosp_week.loc[index, 'Abs_Trend_3w'] = hosp_week.loc[index, 'Abs_Trend'].shift(-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3eab65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_week = hosp_week.rename(columns = {'Abs_Trend_3w' : 'Abs_Trend_target_3w'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ae346230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(hosp_week[['state_name', 'fips', 'Week', 'Week_start', 'Week_end', 'Abs_Trend_target_3w']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1115023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(cwd + '/processed_data/all_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57055c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
